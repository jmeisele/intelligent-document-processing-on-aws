# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: MIT-0

notes: Criteria validation configuration for healthcare/insurance prior authorization
assessment:
  enabled: true
  validation_enabled: false
criteria_validation:
  model: us.anthropic.claude-3-5-sonnet-20240620-v1:0
  temperature: 0.0
  top_k: 20
  top_p: 0.01
  max_tokens: 4096
  semaphore: 3  # Number of concurrent API calls
  max_chunk_size: 180000  # Maximum tokens per chunk
  token_size: 4  # Average characters per token
  overlap_percentage: 10  # Chunk overlap percentage
  response_prefix: "<response>"
  
  # Main validation prompt
  system_prompt: |
    You are a specialized insurance evaluator tasked with determining the eligibility of insurance coverage based on a patient's user history and a set of criterias. 
    Each evaluation should be supported by precise reasoning, with citations from the user history where applicable.
  
  task_prompt: |
    Consider the patients user history inforamtion provided insided <user_history></user_history> XML tags.

    <user_history>
     <source_filepath>
     {source_filepath}
     </source_filepath>

     <content>
     {content}
     </content>
    </user_history>

    <criteria>
    <criteria_type>
    {criteria_type}
    </criteria_type>

    <question>
    {question}
    </question>
    </criteria>

    <instruction>
    Evaluate the patient's insurance eligibility for each question provided insided <question></question> XML tags  and patients user history information provided inside <user_history></user_history> XML tags. 

    Your Task:

    For each question, provide:

    Decision: Carefully review each requirement in the context of the patient's user history to decide if it is "Pass," "Fail," or "Information Not Found" and select one of the following options:

    {recommendation_options}

    Reasoning: Provide a brief explanation for the decision, highlighting any relevant details or absence of data.
    Citations: When applicable, cite specific sections of the user history (e.g., page numbers, sections, S3 URI) that support your decision.

    Json Response format:
    {{
     "criteria_type" : "question/criteria type mentioned inside <criteria_type></criteria_type> XML tags"
     "source_file" : ["list of source_filepath that supports the recommendation"]
     "question" : "question Description"
     "Recommendation" : "This should be one of the following: Pass, Fail, or Information Not Found"
     "Reasoning" : "Provide a thorough explanation, reasoning, and any citations from the source_file in a Single  paragraph explanation without line breaks"
    }}
    All fields must be included in the JSON response, even if some values are unavailable (leave them as empty strings if necessary).
    Ensure that the output is a valid JSON object and strictly adheres to the format provided above.
    criteria_type must be included as a field within the JSON and not as the primary key.
    The reasoning field must include detailed explanations and citations to support the decision.

    </instruction>

    Follow instructions provided inside <instruction></instruction> XML tags. 
    Provide the output in a Json format inside <response></response> XML tags. Do not include any space after <response> tag and before </response> tag.

  # Criteria definitions nested under criteria_validation
  criteria:
    administration_requirements:
      - "Will the immunotherapy be administered under the supervision of an appropriately trained physician?"
      - "Is the facility equipped to treat anaphylaxis?"
      - "Has the physician determined an appropriate dosage regimen and progression schedule?"
      - "Are there adequate safety protocols in place for infusion reactions?"
    medical_necessity:
      - "Has the patient failed standard treatments?"
      - "Is the proposed treatment medically necessary?"
      - "Does the patient meet the clinical criteria for this treatment?"
    dosage_requirements:
      - "Is the dosage appropriate for the patient's condition?"
      - "Has the physician documented the rationale for the selected dosage?"
      - "Are dosage adjustments based on patient response documented?"
    safety_requirements:
      - "Are safety protocols adequate for the proposed treatment?"
      - "Has the patient been screened for contraindications?"
      - "Are monitoring procedures in place during treatment?"
    
    # Recommendation options under criteria
    recommendation_options: |
      Pass: The requirement criteria are fully met.
      Fail: The requirement is partially met or requires additional information.
      Information Not Found: No relevant data exists in the user history.

# Summary configuration for multiple files
summary:
  system_prompt: |
    You are a specialized patient user insurance auth request evaluator
    You will assist in summarizing important patient user insurance auth request information determining the eligibility of insurance coverage based on a patient's user history and a set of questions/criterias. 
    You will be given a question (<question>) and the initial LLM responses (<initial_response>) that has information for one or more patient user history text documents.
    Your task is to evaluate and identify the important and relevant information from the related information to sufficiently answer the given question/criteria.
  
  task_prompt: |
    <criteria>
    <criteria_type>{criteria_type}</criteria_type>
    <question>{question}</question>
    </criteria

    <initial_response>
    {initial_response}
    </initial_response>

    <instructions>
    Analyze the provided criteria and initial response to generate a consolidated final evaluation, considering all available evidence to reach a single determination for each unique criterion.
    Multiple instances of the same question/criteria may appear within a category, often referencing different source files. 

    {recommendation_options}

    JSON RESPONSE FORMAT 

    {{
     "criteria_type" : "question/criteria type mentioned inside <criteria_type></criteria_type> XML tags"
     "source_file" : ["list of source_filepath that supports the recommendation"]
     "question" : "question Description"
     "Recommendation" : "This should be one of the following: Pass, Fail, or Information Not Found"
     "Reasoning" : "Provide a thorough explanation, reasoning, and any citations from the source_file in a Single paragraph explanation without line breaks"
    }}

    SOURCE FILE RULES:
    1. Include ONLY files that contain relevant information for the question/criteria
    2. If no information is found, source_file should be an empty list []
    3. For 'Fail' recommendations, include files that were reviewed and led to the failure decision
    4. For partial information, include only files containing the relevant documentation
    5. Cite specific evidence from each listed file in the reasoning

    RESPONSE RULES:
    1. Provide a single consolidated evaluation
    2. Include all source files that support the recommendation
    3. Keep reasoning concise and in a single paragraph
    4. Use only basic punctuation (. , : ;)
    5. Avoid special characters or line breaks in reasoning
    6. Base recommendation strictly on documented evidence
    7. All JSON fields must be included
    8. For 'Fail' or partial findings, explicitly state what documentation was missing or insufficient

    EVALUATION STEPS:
    1. Review initial response and evidence
    2. Identify files containing relevant information
    3. Determine final recommendation
          - If evidence clearly shows PASS, mark as PASS
          - If any evidence indicates FAIL, mark as FAIL
          - If mixed FAIL and "Information Not Found" for same criteria, use FAIL
          - Only use "Information Not Found" if no evidence at all is found
    4. List only files with supporting evidence
    5. Summarize reasoning with specific citations
    6. Format response as valid JSON

    </instruction>
    Follow instructions provided inside <instruction></instruction> XML tags. 
    Let's think step by step to analyze the question/criteria.
    Provide the output in a Json format inside <response></response> XML tags.

# Criteria types to validate
criteria_types:
  - administration_requirements
  - medical_necessity
  - dosage_requirements
  - safety_requirements

# S3 bucket configuration
request_bucket: criteria-validation-user-history
request_history_prefix: Prior-Auth
criteria_bucket: criteria-validation-criteria
output_bucket: criteria-validation-output
textract_page_tracker: criteria-validation-textract
cost_report_bucket: criteria-validation-cost-reports

discovery:
  output_format:
    sample_json: |-
      {
          "document_class" : "Form-1040",
          "document_description" : "Brief summary of the document",
          "groups" : [
              {
                  "name" : "PersonalInformation",
                  "description" : "Personal information of Tax payer",
                  "attributeType" : "group",
                  "groupAttributes" : [
                      {
                          "name": "FirstName",
                          "dataType" : "string",
                          "description" : "First Name of Taxpayer"
                      },
                      {
                          "name": "Age",
                          "dataType" : "number",
                          "description" : "Age of Taxpayer"
                      }
                  ]
              },
              {
                  "name" : "Dependents",
                  "description" : "Dependents of taxpayer",
                  "attributeType" : "list",
                  "listItemTemplate": {
                      "itemAttributes" : [
                          {
                              "name": "FirstName",
                              "dataType" : "string",
                              "description" : "Dependent first name"
                          },
                          {
                              "name": "Age",
                              "dataType" : "number",
                              "description" : "Dependent Age"
                          }
                      ]
                  }
              }
          ]
      }
  with_ground_truth:
    top_p: '0.1'
    temperature: '1.0'
    user_prompt: >-
      This image contains unstructured data. Analyze the data line by line using the provided ground truth as reference.                        
      <GROUND_TRUTH_REFERENCE>
      {ground_truth_json}
      </GROUND_TRUTH_REFERENCE>
      Ground truth reference JSON has the fields we are interested in extracting from the document/image. Use the ground truth to optimize field extraction. Match field names, data types, and groupings from the reference.
      Image may contain multiple pages, process all pages.
      Extract all field names including those without values.
      Do not change the group name and field name from ground truth in the extracted data json.
      Add field_description field for every field which will contain instruction to LLM to extract the field data from the image/document. Add data_type field for every field. 
      Add two fields document_class and document_description. 
      For document_class generate a short name based on the document content like W4, I-9, Paystub. 
      For document_description generate a description about the document in less than 50 words.
      If the group repeats and follows table format, update the attributeType as "list".                         
      Do not extract the values.
      Format the extracted data using the below JSON format:
      Format the extracted groups and fields using the below JSON format:

    model_id: us.amazon.nova-pro-v1:0
    system_prompt: >-
      You are an expert in processing forms. Extracting data from images and
      documents. Use provided ground truth data as reference to optimize field
      extraction and ensure consistency with expected document structure and
      field definitions.
    max_tokens: '10000'
  without_ground_truth:
    top_p: '0.1'
    temperature: '1.0'
    user_prompt: >-
      This image contains forms data. Analyze the form line by line.
      Image may contains multiple pages, process all the pages. 
      Form may contain multiple name value pair in one line. 
      Extract all the names in the form including the name value pair which doesn't have value. 
      Organize them into groups, extract field_name, data_type and field description
      Field_name should be less than 60 characters, should not have space use '-' instead of space.
      field_description is a brief description of the field and the location of the field like box number or line number in the form and section of the form.
      Field_name should be unique within the group.
      Add two fields document_class and document_description. 
      For document_class generate a short name based on the document content like W4, I-9, Paystub. 
      For document_description generate a description about the document in less than 50 words. 

      Group the fields based on the section they are grouped in the form. Group should have attributeType as "group".
      If the group repeats and follows table format, update the attributeType as "list".
      Do not extract the values.
      Return the extracted data in JSON format.
      Format the extracted data using the below JSON format:
      Format the extracted groups and fields using the below JSON format:
    model_id: us.amazon.nova-pro-v1:0
    system_prompt: >-
      You are an expert in processing forms. Extracting data from images and
      documents. Analyze forms line by line to identify field names, data types,
      and organizational structure. Focus on creating comprehensive blueprints
      for document processing without extracting actual values.
    max_tokens: '10000'

agents:
  error_analyzer:
    model_id: us.anthropic.claude-sonnet-4-20250514-v1:0

    system_prompt: |-
      You are an intelligent error analysis agent for the GenAI IDP system.

      Use the analyze_errors tool to investigate issues. ALWAYS format your response with exactly these three sections in this order:

      ## Root Cause
      Identify the specific underlying technical reason why the error occurred. Focus on the primary cause, not symptoms.

      ## Recommendations
      Provide specific, actionable steps to resolve the issue. Limit to top three recommendations only.

      <details>
      <summary><strong>Evidence</strong></summary>

      Format log entries with their source information. For each log entry, show:
      **Log Group:**  
      [full log_group name from tool response]

      **Log Stream:**  
      [full log_stream name from tool response]
      ```
      [ERROR] timestamp message (from events data)
      ```

      </details>

      FORMATTING RULES:
      - Use the exact three-section structure above
      - Make Evidence section collapsible using HTML details tags
      - Extract log_group, log_stream, and events data from tool response
      - Show complete log group and log stream names without truncation
      - Present actual log messages from events array in code blocks
  
      ANALYSIS GUIDELINES:
      - If has_performance_issues is false, focus on application logic errors
      - Use service timeline to rule out infrastructure bottlenecks
      - Service response times help eliminate timeout-related causes
      - For application errors use CloudWatch error messages for recommendations
      
      ROOT CAUSE DETERMINATION:
      - Start with Step Function failure details (most specific)
      - Validate with CloudWatch error logs (most detailed)
      - Use X-Ray to categorize as infrastructure vs. application issue
      - DynamoDB provides supporting timeline context only
      
      RECOMMENDATION GUIDELINES:
      For code-related issues or system bugs:
      - Do not suggest code modifications
      - Include error details, timestamps, and context

      For configuration-related issues:
      - Direct users to UI configuration panel
      - Specify exact configuration section and parameter names

      For operational issues:
      - Provide immediate troubleshooting steps
      - Include preventive measures

      TIME RANGE PARSING:
      - recent/recently: 1 hour
      - last week: 168 hours  
      - last day/yesterday: 24 hours
      - No time specified: 24 hours (default)

      SPECIAL CASES:
      If analysis_type is "document_not_found": explain document cannot be located, focus on verification steps and processing issues.

      DO NOT include code suggestions, technical summaries, or multiple paragraphs of explanation. Keep responses concise and actionable.

      IMPORTANT: Do not include any search quality reflections, search quality scores, or meta-analysis sections in your response. Only provide the three required sections: Root Cause, Recommendations, and Evidence.
    parameters:
      max_log_events: 5
      time_range_hours_default: 24

# Pricing configuration for cost tracking
pricing:
  - name: textract/detect_document_text
    units:
      - name: first_million_pages
        price: 0.0015
      - name: over_million_pages
        price: 0.0006
  - name: bedrock/us.anthropic.claude-3-5-sonnet-20240620-v1:0
    units:
      - name: inputTokens
        price: 0.000003
      - name: outputTokens
        price: 0.000015
      - name: cacheReadInputTokens
        price: 0.0000003
      - name: cacheWriteInputTokens
        price: 0.00000375
  - name: bedrock/us.amazon.nova-pro-v1:0
    units:
      - name: inputTokens
        price: 0.0000008
      - name: outputTokens
        price: 0.0000032
      - name: cacheReadInputTokens
        price: 0.0000002
  # AWS Lambda pricing (US East - N. Virginia)
  - name: lambda/requests
    units:
      - name: invocations
        price: '2.0E-7'       # $0.0000002 per request ($0.20 per 1M requests)
  - name: lambda/duration  
    units:
      - name: gb_seconds
        price: '1.66667E-5'   # $0.0000166667 per GB-second ($16.67 per 1M GB-seconds)

